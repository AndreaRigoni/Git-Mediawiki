#! /usr/bin/perl

use strict;
use Switch;
use MediaWiki::API;
use Storable qw(freeze thaw);
use DateTime::Format::ISO8601;
use Encode qw(encode_utf8);

my $url = $ARGV[1];

print STDERR "$url\n";

# commands parser
my $loop = 1;
my $entry;
my @cmd;
while ($loop) {
	$| = 1; #flush stdout
	$entry = <STDIN>;
	print STDERR $entry;
	chomp($entry);
	@cmd = undef;
	@cmd = split(/ /,$entry);
	switch ($cmd[0]) {
		case "capabilities" {
			if ($cmd[1] eq "") {
				mw_capabilities();
			}
		}
		case "list" {
			if ($cmd[2] eq "") {
				mw_list($cmd[1]);
			} 
		}
		case "import" {
			if ($cmd[1] ne "" && $cmd[2] eq "") {
				mw_import($url);
			} 
		}
		case "option" {
			mw_option($cmd[1],$cmd[2]);
		}
		case "fetch" {
			mw_fetch($url);
		}
		case "push" {
			#check the pattern +<src>:<dist>
			my @pushargs = split(/:/,$cmd[1]);
			if ($pushargs[1] ne "" && $pushargs[2] eq "" 
			&& (substr($pushargs[0],0,1) eq "+")) {	
				print "kikoo";
				mw_push(substr($pushargs[0],1),$pushargs[1]);
			}
		}
		else {
			$loop = 0;
			close(FILE);
		}
	}
}

sub mw_capabilities {
#	print STDOUT "fetch\n";
	print STDOUT "import\n";
	print STDOUT "list\n";
	print STDOUT "option\n";
	print STDOUT "push\n";
	print STDOUT "\n";
}

sub mw_list {
	print STDOUT "? refs/heads/master\n";
#	if ($_[0] eq "") { # call to list and not list for push
	print STDOUT '@'."refs/heads/master HEAD\n";
#	}
	print STDOUT "\n";

}

sub mw_option {
	print STDERR "not yet implemented \n";
	print STDOUT "unsupported\n";
}

sub mw_fetch {
	print "\n";
}

sub mw_import {
	my $url = $_[0];

	my $mediawiki = MediaWiki::API->new;
	$mediawiki->{config}->{api_url} = "$url/api.php";

	my $pages = $mediawiki->list({
			action => 'query',
			list => 'allpages',
			aplimit => 500,
		});

	my @revisions;

	print STDERR "Fetching revisions...\n";
	my $n = 1;

	foreach my $page (@$pages) {
		my $id = $page->{pageid};

		print STDERR "$n/", scalar(@$pages), ": $page->{title}\n";
		$n++;

		my $query = {
			action => 'query',
			prop => 'revisions',
			rvprop => 'ids',
			rvlimit => 500,
			pageids => $page->{pageid},
		};

		my $revnum = 1;
		# Get 500 revisions at a time
		while (1) {
			my $result = $mediawiki->api($query);

			# Parse each of those 500 revisions
			foreach my $revision (@{$result->{query}->{pages}->{$id}->{revisions}}) {
				my $page_rev_ids;
				$page_rev_ids->{pageid} = $page->{pageid};
				$page_rev_ids->{revid} = $revision->{revid};
				push (@revisions, $page_rev_ids);
				$revnum++;
			}

			last unless $result->{'query-continue'};
			$query->{rvstartid} = $result->{'query-continue'}->{revisions}->{rvstartid};
			print "\n";
		}

		print STDERR "  Fetched ", $revnum, " revisions.\n";

	}


# Creation of the fast-import stream
	print STDERR "Writing export data...\n";
	binmode STDOUT, ':binary';
	$n = 0;

	foreach my $pagerevids (sort {$a->{revid} >= $b->{revid}} @revisions) {

		my $query = {
			action => 'query',
			prop => 'revisions',
			rvprop => 'content|timestamp|comment|user|ids',
			revids => $pagerevids->{revid},
		};

		my $result = $mediawiki->api($query);

		my $rev = pop(@{$result->{query}->{pages}->{$pagerevids->{pageid}}->{revisions}});

		$n++;
		my $user = $rev->{user} || 'Anonymous';
		my $dt = DateTime::Format::ISO8601->parse_datetime($rev->{timestamp});

		my $comment = defined $rev->{comment} ? $rev->{comment} : '*Empty MediaWiki Message*';
		my $title = $result->{query}->{pages}->{$pagerevids->{pageid}}->{title};
		my $content = $rev->{'*'};
		$title =~ y/ /_/;

		print STDERR "$n/", scalar(@revisions), ": $title\n";

		print "commit refs/heads/master\n";
		print "mark :$n\n";
		print "committer $user <none\@example.com> ", $dt->epoch, " +0000\n";
		print "data ", bytes::length(encode_utf8($comment)), "\n", encode_utf8($comment);
		print "M 644 inline $title.wiki\n";
		print "data ", bytes::length(encode_utf8($content)), "\n", encode_utf8($content);
		print "\n\n";

	}

	print "reset refs/heads/master\n";
	print "from :$n";


}

sub mw_push {
	print STDERR "not yet implemented \n";
}


1;
